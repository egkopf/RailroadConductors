#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jul 23 13:50:26 2019

@author: ethankopf
"""



# Include these packages to support both python 2 and python 3
from __future__ import division, print_function, unicode_literals

# Other packages that we need to import for use in our script
import numpy as np
import os
import pandas as pd

# to make this script's output stable across runs, we need to initialize the random number generator to the same starting seed each time
np.random.seed(42)

# To save nice figures
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt


####################
# STEP 1: OBTAIN THE DATA
####################

# Now, we need to download a dataset to work with
# The sklearn package has a function that can download the data for us:
#from sklearn.datasets import fetch_mldata

RailroadData = pd.read_excel("/Users/ethankopf/Desktop/Dispatchers_Background_Data 3.xlsx")


HealthStatus = RailroadData['Health_status'].values.astype(np.float)
ID = RailroadData['ID'].values
Sex = RailroadData['Sex'].values.astype(np.float)
CaffBeverages = RailroadData['Caff_Beverages'].values.astype(np.float)
SleepApnea = RailroadData['Sleep_Apnea'].values.astype(np.float)
AgeGroup = RailroadData['Age_Group'].values.astype(np.float)
TotalYearsDispatcher = RailroadData['Total_years_dispatcher'].values.astype(np.float)
MaritalStatus = RailroadData['Marital_Status'].values.astype(np.float)
Childrendependents = RailroadData['Childrendependents'].values.astype(np.float)
DiagnosedSleepDisorder = RailroadData['Diagnosed_Sleep_disorder'].values.astype(np.float)
AvgWorkHrsWeek = RailroadData['Avg_Work_Hrs_Week'].values.astype(np.float)
MentallyDrained = RailroadData['Mentally_Drained'].values.astype(np.float)
JobPressure = RailroadData['Job_pressure'].values.astype(np.float)
TotalLifeEvents = RailroadData['Total_life_events'].values.astype(np.float)
NumCaffBev = RailroadData['Num_Caff_Bev'].values.astype(np.float)

    
TrainPatients = []  
for i in range(0, 354):
    TrainPatients.append([AgeGroup[i], Sex[i], AgeGroup[i], TotalYearsDispatcher[i], MaritalStatus[i], Childrendependents[i], AvgWorkHrsWeek[i], MentallyDrained[i], JobPressure[i], TotalLifeEvents[i], NumCaffBev[i]])

TestPatients = []
for i in range(354, 443):
    TestPatients.append([AgeGroup[i], Sex[i], AgeGroup[i], TotalYearsDispatcher[i], MaritalStatus[i], Childrendependents[i], AvgWorkHrsWeek[i], MentallyDrained[i], JobPressure[i], TotalLifeEvents[i], NumCaffBev[i]])

print(TrainPatients)
# Now we see that our matrix has 70,000 rows, meaning it describes 70,000
# handwritten numbers. The matrix has 728 columns, so each of the 70,000
# handwritten numbers in our database is described by 728 data points. These points
# define a 28 pixel x 28 pixel square. There is one data point for each pixel in the
# square, which gives the shade of gray in that square (anything from white to black
# and all the shades of gray in-between). If we were to graph a figure using the data
# for one of those handwritten numbers, we would get a 28x28 sized square that depicts
# a single hand-written number.

####################
# STEP 2: EXPLORE THE DATA
####################

# TO DO: Import the plotting package matplotlib. Uncomment the following
#      two lines to import matplotlib and to have a short way to refer
#      to its subpackage pyplot:
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# TO DO: Let's look at one of the numbers described in our matrix. First, define a new variable called 'some_digit' that is equal to one of the rows of data in matrix X:

# TO DO: Now, we need to reshape that row into a square, the 28x28 square that can
#      represent the picture of that handwritten number. We can do this in two
#      steps. First take a subset of our X variable, where we define the row
#      and column indices we want in our subset. We want to use the value of
#      some_digit as our row. And we want all columns (all indices in the row) to
#      be included in our data subset, so keep in mind that the argument we provide
#      for the column argument of X will not be a single number.
#      After slicing the X matrix to get the data from a single row, we can
#      call the reshape function of that subset, which takes two arguments,
#      the row and column dimensions to reshape our variable into, and save
#      this reshaped subset as a new variable, some_digit_image:
# some_digit_image = np.reshape(X[some_digit,:],[28,28])

def print_row(row):
    row -= 2
    print("ID: ", ID[row] , '\n\tAge Group: ', AgeGroup[row] , "\n\tSex: ", Sex[row], "\n\tTotal Years Dispatcher: ", TotalYearsDispatcher[row], "\n\tMarital Status: ", MaritalStatus[row], "\n\tChildrendependents: ", Childrendependents[row], "\n\tCaff Beverage: ", CaffBeverages[row], "\n\tHealth Status: ", HealthStatus[row], "\n\tDiagnosed Sleep Disorder: ", DiagnosedSleepDisorder[row], "\n\tSleep Apnea: ", SleepApnea[row], '\n\tAvg Work Hrs Week: ', AvgWorkHrsWeek[row], "\n\tMentally Drained: ", MentallyDrained[row], "\n\tJob Pressure: ", JobPressure[row], "\n\tTotal Life Events: ", TotalLifeEvents[row], "\n\tNum Caff Bev: ", NumCaffBev[row])  

####################
# STEP 2: SEPARATE TRAINING AND TEST DATA
####################

# TO DO: We need to separate both our number data matrix (X) and
#      the vector of labels that contains the true identity of
#      each number (y). We have 70,000 numbers total, so lets
#      use 60,000 numbers for training and 10,000 for test.
#      Use your knowledge of slicing arrays to select the first
#      60,000 numbers for training and the last 10,000 for testing:
    

Train_Sleep_Apnea = SleepApnea[0:354]
Test_Sleep_Apnea = SleepApnea[354:445]

#print(Train_Sleep_Apnea)
#print(Train_Caff_Beverages)


# print(Train_Sleep_Apnea)
# print(Train_Caff_Beverages)
# print(Test_Sleep_Apnea)
# print(Test_Caff_Beverages)

from sklearn.linear_model import SGDClassifier

# TO DO: Now, we need to call the SGDClassifier. This function
#      requires two named arguments, max_iter and random_state.
#      The max_iter argument sets the maximum number of
#      iterations to perform while learning the task (it is
#      a coincidence that this number should be set to 5). The
#      random_state argument lets us specify a random seed
#      to use to initialize our network. Lets use 42. Set the
#      output of the function to 'sgd_clf'. This represents
#      our learning algorithm object.
#
sgd_clf = SGDClassifier(max_iter=5, random_state=42, loss = "modified_huber")

# TO DO: Next, we need to provide our learning algorithm with the
#      training data and its corresponding labels. Because we
#      created a new vector called y_train_5, our labels for this
#      task are no longer the actual number represented by the
#      training data, but are instead all set to 0 for numbers
#      that are not 5 and to 1 for numbers that are 5.  Call the
#      fit() method of the sgd_clf object with two arguments, the
#      training data set and the new label vector (with 0 for non-5
#      and 1 for 5).
sgd_clf.fit(TrainPatients, Train_Sleep_Apnea)

# TO DO: Now let's see what our trained algorithm thinks that strange
#      looking number is. Uncomment and run the following code to
#      find out:

print(sgd_clf.predict(TestPatients))
print(Test_Sleep_Apnea)


####################
# STEP 5: EVALUATE THE NETWORK PERFORMANCE
####################

# To DO: Now we want to measure the performance of the training algorithm
#      taking into account all of the training data. We can find out the
#      exact performance of the algorithm because we know the real identities
#      of the number samples and we know what the algorithm came up with
#      for each sample. We need to import the function 'cross_val_score'
#      from sklearn.model_selection and then call that function with the
#      arguments 'sgd_clf' (the learning algorithm object), our training
#      dataset (X_train), our label vector that labels whether each training row
#      is a 5 or not a 5 (called y_train_5, don't use the other vector y_train
#      for this exercise), and two named arguments: cv=3, scoring="accuracy"

from sklearn.model_selection import cross_val_score
performance = cross_val_score(sgd_clf, TestPatients, Test_Sleep_Apnea, cv=3, scoring="accuracy")
print("cross_val_score = ", performance)


# Before we go any further, refer back to the steps in Exercise 1 of the
# Machine Learning lab in your lab manual. Let's discuss the performance
# of the model and then see how we can better measure the performance.
#
# Important concepts here are:
# - precision: accuracy of the positive predictions of the model. When
#           the model says a number is a "5", how often is it right?
# - recall: sensitivity of the model. How many "5"s in the dataset does
#           it correctly detect?
#
# When we calculated the cross_val_score above, it looks really good at
# over 90% accuracy. But that is only because the 5s make up about 10% of
# the dataset. If it just categorizes every single number as "not-5", then
# it already achieves 90% accuracy without doing anything useful.

# TODO: A better measure of performance is the confusion matrix (discussed in your
#     lab manual and the pre-lab lecture). To produce a confusion matrix that
#     will give us a better indication of the model performance, import the
#     confusion_matrix function from sklearn.metrics and then call that function
#     with two arguments, the target classifications (y_train_5) and the predicted
#     classifications (y_train_pred):
from sklearn.metrics import confusion_matrix, precision_score, recall_score
newperformance = confusion_matrix(Test_Sleep_Apnea, sgd_clf.predict(TestPatients))
print(newperformance)
#
# We can also calculate values for precision and recall directly, by importing and
# using the precision_score and recall_score functions from sklearn.metrics (and
# passing in the same two arguments as when we called the confusion_matrix function)
precision = precision_score(Test_Sleep_Apnea, sgd_clf.predict(TestPatients))
recall = recall_score(Test_Sleep_Apnea, sgd_clf.predict(TestPatients))
print("precision = ", precision, ", recall = ", recall)

# The model performance is a balance between precision and recall. If we alter the
# sensitivity of the model, we can increase precision but at the expense of recall,
# and vice versa. Sometimes people combine these two performance measures into a
# single performance score called the F1 score, which will only be high (desirable)
# if both precision and recall are sufficiently strong. To calculate the F1 score,
# import and use the f1_score function from sklearn.metrics:
from sklearn.metrics import f1_score
f1performance = f1_score(Test_Sleep_Apnea, sgd_clf.predict(TestPatients))
print("F1 score = ", f1performance)

####################
# STEP 6: MULTICLASS CLASSIFICATION TASK
####################

# Now we can perform a more intuitive machine learning task on our data. Our dataset
# contains ten different digits, so it makes sense to allow for the classification of
# each digit into a category for its own identity. There are several ways to approach this
# task. We can either use an algorithm that inherently supports multiclassification. Or
# we can use a combination of binary classifiers to sort our data into multiple classes.
#
# If we use a combination of binary classifiers, we can go about it in two different ways.
# We can either train one binary classifier on each target label in the dataset, and subject
# each datum to every binary classifier; the one with the highest score "wins." This is
# called "one-versus-all" or OvA. Or we can train binary classifiers for every possible
# pair of digits (ex: 0 or 1? 0 or 2? 1 or 2? 0 or 3? ... and so on). For the MNIST dataset,
# this means 45 different binary "competitions." Each digit has to be run through all 45
# of these competitions, and whichever digit classifier wins the most of them is then considered
# the predicted class of that digit. This technique is refered to as "one-versus-one" or OvO.
# Which technique you use depends on the type of binary classifier you are using and the
# properties and size of your dataset.
#
# Let's compare the performance of two different approaches to multiclassification:
# - using a set of binary classifiers in an OvA configuration
# - using a multiclassifier
#
# TODO: Use the SDGclassifier again. This time, we will be working with y_train labels
#     (not y_train_5 labels). Scroll or "find" many lines back in this script where
#     you used the "fit" and "predict" functions of the sgd_clf class. Use them again
#     here with the same data (X_train) and the appropriate set of labels (y_train).
#sgd_clf.fit(X_train, y_train)
#sgd_clf.predict(X_train)

# TODO: Now see how this algorithm does on that same digit we used before, except now the
#     algorithm is performing a multiclassification task. Uncomment the next two lines:
#some_digit_scores = sgd_clf.decision_function([some_digit])
#print("scores for some_digit=", some_digit_scores)
#
# Notice that scores are returned for each potential label of the digit, from 0 to 9.
# Which score is the highest?
#
# TODO: To programmatically arrive at the highest-scoring category, uncomment these lines
#     of code. Try to understand what each line does as you uncomment it:
#n = np.argmax(some_digit_scores)
#prediction = sgd_clf.classes_[n]

# Now, let's try another approach, a multiclassifier algorithm called Random Forest.

# TODO: call training function (fit) and a prediction function (prediction) for the
#     random forest classifier (forest_clf), passing in the same arguments as when
#     we used the previous algorithm:

#from sklearn.ensemble import RandomForestClassifier
#forest_clf = RandomForestClassifier(random_state=42)
#forest_clf.fit(X_train, y_train)
#forest_prediction = forest_clf.predict(X_train)

# This function called directly gave us the predicted label for our "some_digit". But
# what if we want to see how it rated all the possible options? If we want to see the
# scores assigned to each potential label, we can run this line of code to get them:
#possible_scores = forest_clf.predict_proba([some_digit])
#print(possible_scores)

# So we saw how each of these algorithms assigned our some_digit, and the relative scores
# each algorithm gave all 10 possible classifications for some_digit. What if we want
# to measure the performance of the algorithms on our test data?
#
# TODO: Compute the cross_val_score on our revised sgd_clf and on our forest_clf algorithms,
#     supplying the same types of arguments as we did previously when we computed the
#     cross_val_score for our 5/not-5 binary classification. Except that instead of y_train_5
#     labels, we will this time supply y_train for our labels argument to the function. You
#     may need to scroll or "find" back up in the code to see how you called cross_val_score
#     previously:
# sgd_score = ...
# forest_score = ...

# You are welcome to compare other performance metrics for these two algorithms. Which algorithm
# would you say works better for multiclassification of the MNIST dataset and why?
